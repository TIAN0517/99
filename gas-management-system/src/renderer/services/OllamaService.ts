import axios from 'axios';

// AI æ¨¡å‹é…ç½® - é’ˆå¯¹ä¸åŒå†…å­˜ç¯å¢ƒä¼˜åŒ–
export interface AIModelConfig {
    name: string;
    minMemoryGB: number;
    description: string;
    capabilities: string[];
}

export const AI_MODELS: Record<string, AIModelConfig> = {
    'llama3:8b-instruct-q4_0': {
        name: 'llama3:8b-instruct-q4_0',
        minMemoryGB: 5.2,
        description: 'ğŸ¦™ Llama3 8BæŒ‡ä»¤å¾®è°ƒæ¨¡å‹ - é«˜æ€§èƒ½å¯¹è¯å’Œæ¨ç†',
        capabilities: ['ä¸­æ–‡å¯¹è¯', 'è‹±æ–‡å¯¹è¯', 'ä»£ç ç”Ÿæˆ', 'å¤æ‚æ¨ç†', 'ä¸šåŠ¡åˆ†æ', 'æŒ‡ä»¤è·Ÿéš']
    },
    'deepseek-r1:8b': {
        name: 'deepseek-r1:8b',
        minMemoryGB: 6.6,
        description: 'é«˜æ€§èƒ½æ¨ç†æ¨¡å‹ï¼Œæ”¯æŒå¤æ‚æŸ¥è¯¢',
        capabilities: ['ä¸­æ–‡å¯¹è¯', 'ä»£ç ç”Ÿæˆ', 'å¤æ‚æ¨ç†', 'ä¸šåŠ¡åˆ†æ']
    },
    'gemma:2b': {
        name: 'gemma:2b',
        minMemoryGB: 2.5,
        description: 'è½»é‡çº§æ¨¡å‹ï¼Œé€‚åˆä½å†…å­˜ç¯å¢ƒ',
        capabilities: ['ä¸­æ–‡å¯¹è¯', 'åŸºç¡€æŸ¥è¯¢', 'æ–‡æœ¬ç”Ÿæˆ']
    },
    'phi3:mini': {
        name: 'phi3:mini',
        minMemoryGB: 2.0,
        description: 'å¾®å‹æ¨¡å‹ï¼Œæœ€ä½å†…å­˜éœ€æ±‚',
        capabilities: ['ç®€å•å¯¹è¯', 'åŸºç¡€é—®ç­”']
    }
};

// è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ¨¡å‹
export function selectOptimalModel(availableMemoryGB: number): string {
    if (availableMemoryGB >= 6.6) {
        return 'deepseek-r1:8b';
    } else if (availableMemoryGB >= 5.2) {
        return 'llama3:8b-instruct-q4_0';
    } else if (availableMemoryGB >= 2.5) {
        return 'gemma:2b';
    } else {
        return 'phi3:mini';
    }
}

// Ollama API æœå‹™é›†æˆ - VPS ä¼˜åŒ–ç‰ˆ
export class OllamaService {
    private baseUrl: string = 'http://localhost:11434';
    private model: string;
    private retryCount = 0;
    private maxRetries = 3;
    constructor(baseUrl?: string, model?: string) {
        if (baseUrl) this.baseUrl = baseUrl;

        // æ ¹æ®ç¯å¢ƒè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ¨¡å‹
        if (model) {
            this.model = model;
        } else {
            this.model = this.detectOptimalModel();
        }
    }    /**
     * æ£€æµ‹æœ€ä½³æ¨¡å‹ - åŸºäºå†…å­˜é™åˆ¶
     */
    private detectOptimalModel(): string {
        // ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ Llama3 æ¨¡å‹
        if (typeof window !== 'undefined') {
            return 'llama3:8b-instruct-q4_0';
        }

        try {
            // åœ¨ Node.js ç¯å¢ƒä¸­å°è¯•æ£€æŸ¥ç³»ç»Ÿå†…å­˜
            const os = require('os');
            const totalMemoryGB = os.totalmem() / (1024 * 1024 * 1024);
            console.log(`ğŸ–¥ï¸ ç³»ç»Ÿå†…å­˜: ${totalMemoryGB.toFixed(1)}GB`);
            return selectOptimalModel(totalMemoryGB);
        } catch {
            // é»˜è®¤ä½¿ç”¨é«˜æ€§èƒ½ Llama3 æ¨¡å‹
            console.log('ğŸ¤– ä½¿ç”¨é»˜è®¤é«˜æ€§èƒ½æ¨¡å‹: llama3:8b-instruct-q4_0');
            return 'llama3:8b-instruct-q4_0';
        }
    }
    /**
     * æª¢æŸ¥ Ollama æœå‹™æ˜¯å¦å¯ç”¨ - å¢å¼ºç‰ˆ
     */
    async isAvailable(): Promise<boolean> {
        try {
            const response = await fetch(`${this.baseUrl}/api/tags`, {
                method: 'GET',
                headers: {
                    'Content-Type': 'application/json',
                },
            });

            if (!response.ok) {
                console.error(`âŒ Ollama API é”™è¯¯: ${response.status}`);
                return false;
            }

            const data = await response.json();
            console.log('ğŸ¤– å¯ç”¨æ¨¡å‹:', data.models?.map((m: any) => m.name) || []);

            // æ£€æŸ¥å½“å‰æ¨¡å‹æ˜¯å¦å¯ç”¨
            const availableModels = data.models?.map((m: any) => m.name) || [];
            if (!availableModels.includes(this.model)) {
                // å¦‚æœå½“å‰æ¨¡å‹ä¸å¯ç”¨ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨çš„è½»é‡çº§æ¨¡å‹
                const fallbackModel = availableModels.find((model: string) =>
                    model.includes('gemma') ||
                    model.includes('phi3') ||
                    model.includes('llama2') ||
                    model.includes('tinyllama')
                );

                if (fallbackModel) {
                    console.log(`ğŸ”„ åˆ‡æ¢åˆ°å¯ç”¨æ¨¡å‹: ${fallbackModel}`);
                    this.model = fallbackModel;
                } else if (availableModels.length > 0) {
                    console.log(`ğŸ”„ ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹: ${availableModels[0]}`);
                    this.model = availableModels[0];
                }
            }

            return true;
        } catch (error) {
            console.error('âŒ Ollama æœåŠ¡ä¸å¯ç”¨:', error);
            return false;
        }
    }
    /**
     * ç™¼é€èŠå¤©æ¶ˆæ¯åˆ° Ollama - VPS ä¼˜åŒ–ç‰ˆ
     */
    async chat(message: string, context?: string): Promise<{ message: string; error?: string }> {
        try {
            // æª¢æŸ¥æœå‹™æ˜¯å¦å¯ç”¨
            const available = await this.isAvailable();
            if (!available) {
                return {
                    message: this.getFallbackResponse(message),
                    error: 'Service unavailable'
                };
            }

            console.log(`ğŸ¤– ä½¿ç”¨æ¨¡å‹: ${this.model}`);

            // æ§‹å»ºæç¤ºè©
            const prompt = this.buildPrompt(message, context);

            const response = await fetch(`${this.baseUrl}/api/generate`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    model: this.model,
                    prompt: prompt,
                    stream: false,
                    options: {
                        temperature: 0.7,
                        top_p: 0.9,
                        max_tokens: 300, // é™ä½ token é™åˆ¶ä»¥èŠ‚çœå†…å­˜
                        num_ctx: 1024,   // é™ä½ä¸Šä¸‹æ–‡çª—å£
                    }
                }),
            });

            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
            }

            const data = await response.json();

            if (data.response) {
                this.retryCount = 0; // é‡ç½®é‡è¯•è®¡æ•°
                return {
                    message: data.response,
                };
            } else {
                throw new Error('No response from model');
            }

        } catch (error) {
            console.error('âŒ Ollama chat error:', error);

            if (this.retryCount < this.maxRetries) {
                this.retryCount++;
                console.log(`ğŸ”„ é‡è¯• (${this.retryCount}/${this.maxRetries})...`);
                await new Promise(resolve => setTimeout(resolve, 1000));
                return this.chat(message, context);
            }

            this.retryCount = 0;
            return {
                message: this.getFallbackResponse(message),
                error: error instanceof Error ? error.message : 'Unknown error'
            };
        }
    }

    /**
     * è·å–å¤‡ç”¨å“åº”
     */
    private getFallbackResponse(message: string): string {
        const fallbackResponses = [
            'è‘£å¨˜çš„åŠ©ç†æš‚æ—¶ç¦»çº¿ä¸­ï¼Œè¯·ç¨åå†è¯•ã€‚å¦‚éœ€ç´§æ€¥å¸®åŠ©ï¼Œè¯·è”ç³» JyæŠ€è¡“åœ˜éšŠã€‚',
            'ç³»ç»Ÿæ­£åœ¨æ›´æ–°ä¸­ï¼ŒAI åŠ©ç†æš‚æ—¶ä¸å¯ç”¨ã€‚è¯·æŸ¥çœ‹å¸®åŠ©æ–‡æ¡£æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚',
            'æŠ±æ­‰ï¼ŒAI æœåŠ¡ä¸´æ—¶ä¸­æ–­ã€‚æ‚¨å¯ä»¥ç»§ç»­ä½¿ç”¨ç³»ç»Ÿçš„å…¶ä»–åŠŸèƒ½ã€‚',
            'è‘£å¨˜çš„åŠ©ç†æ­£åœ¨ä¼‘æ¯ï¼Œè¯·ç¨åå†æ¥å’¨è¯¢ã€‚ç³»ç»Ÿå…¶ä»–åŠŸèƒ½æ­£å¸¸è¿è¡Œã€‚'
        ];

        // æ ¹æ®æ¶ˆæ¯ç±»å‹è¿”å›æ›´ç›¸å…³çš„å›å¤
        if (message.includes('ä»·æ ¼') || message.includes('è´¹ç”¨')) {
            return 'ä»·æ ¼æŸ¥è¯¢åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·æŸ¥çœ‹ä»·æ ¼ç®¡ç†é¡µé¢æˆ–è”ç³»å®¢æœã€‚';
        } else if (message.includes('è®¢å•') || message.includes('é…é€')) {
            return 'è®¢å•æŸ¥è¯¢åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·åœ¨è®¢å•ç®¡ç†é¡µé¢æŸ¥çœ‹è¯¦æƒ…ã€‚';
        } else if (message.includes('åº“å­˜') || message.includes('å•†å“')) {
            return 'åº“å­˜æŸ¥è¯¢åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·åœ¨äº§å“ç®¡ç†é¡µé¢æŸ¥çœ‹è¯¦æƒ…ã€‚';
        }

        return fallbackResponses[Math.floor(Math.random() * fallbackResponses.length)];
    }

    /**
     * æ§‹å»ºé‡å°ç“¦æ–¯è¡Œæ¥­å‹™çš„æç¤ºè©
     */
    private buildPrompt(message: string, context?: string): string {
        const systemPrompt = `ä½ æ˜¯"è‘£å¨˜çš„åŠ©ç†"ï¼Œä¸€å€‹å°ˆé–€ç‚ºç“¦æ–¯è¡Œæ¥­å‹™è¨­è¨ˆçš„AIåŠ©æ‰‹ã€‚ä½ å…·å‚™ä»¥ä¸‹å°ˆæ¥­çŸ¥è­˜ï¼š

æ¥­å‹™ç¯„åœï¼š
- æ¶²åŒ–çŸ³æ²¹æ°£(LPG)éŠ·å”®èˆ‡é…é€
- ç“¦æ–¯è¨­å‚™å®‰è£èˆ‡ç¶­è­·
- å®¢æˆ¶æœå‹™èˆ‡è¨‚å–®ç®¡ç†
- åº«å­˜ç®¡ç†èˆ‡æˆæœ¬æ§åˆ¶
- å®‰å…¨è¦ç¯„èˆ‡æ³•è¦éµå¾ª

å›ç­”é¢¨æ ¼ï¼š
- ä½¿ç”¨ç¹é«”ä¸­æ–‡
- èªæ°£è¦ªåˆ‡å°ˆæ¥­
- æä¾›å¯¦ç”¨çš„å»ºè­°
- é—œæ³¨å®‰å…¨èˆ‡æ•ˆç‡

è«‹æ ¹æ“šç”¨æˆ¶çš„å•é¡Œæä¾›å°ˆæ¥­ä¸”å¯¦ç”¨çš„å›ç­”ã€‚

${context ? `æ¥­å‹™èƒŒæ™¯ï¼š${context}` : ''}

ç”¨æˆ¶å•é¡Œï¼š${message}

è‘£å¨˜çš„åŠ©ç†å›è¦†ï¼š`;

        return systemPrompt;
    }

    /**
     * ç²å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
     */
    async getAvailableModels(): Promise<string[]> {
        try {
            const response = await fetch(`${this.baseUrl}/api/tags`);
            if (!response.ok) return [];

            const data = await response.json();
            return data.models?.map((model: any) => model.name) || [];
        } catch (error) {
            console.error('Failed to get models:', error);
            return [];
        }
    }

    /**
     * è¨­ç½®ä½¿ç”¨çš„æ¨¡å‹
     */
    setModel(model: string): void {
        this.model = model;
    }
    /**
     * ç²å–ç•¶å‰ä½¿ç”¨çš„æ¨¡å‹
     */
    getCurrentModel(): string {
        return this.model;
    }

    /**
     * è·å–å½“å‰ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯
     */
    getModelInfo(): AIModelConfig | null {
        return AI_MODELS[this.model] || null;
    }

    /**
     * æ‰‹åŠ¨åˆ‡æ¢æ¨¡å‹
     */
    async switchModel(modelName: string): Promise<boolean> {
        try {
            // æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
            const isAvailable = await this.isAvailable();
            if (!isAvailable) return false;

            const response = await fetch(`${this.baseUrl}/api/tags`);
            const data = await response.json();
            const availableModels = data.models?.map((m: any) => m.name) || [];

            if (availableModels.includes(modelName)) {
                this.model = modelName;
                console.log(`âœ… å·²åˆ‡æ¢åˆ°æ¨¡å‹: ${modelName}`);
                return true;
            } else {
                console.error(`âŒ æ¨¡å‹ä¸å¯ç”¨: ${modelName}`);
                return false;
            }
        } catch (error) {
            console.error('âŒ åˆ‡æ¢æ¨¡å‹å¤±è´¥:', error);
            return false;
        }
    }

    /**
     * ç”Ÿæˆç®€å•å“åº” - å…¼å®¹æ—§ç‰ˆ API
     */
    async generateResponse(message: string): Promise<string> {
        const result = await this.chat(message);
        return result.message;
    }
}

// å‰µå»ºå–®ä¾‹å¯¦ä¾‹
export const ollamaService = new OllamaService();

// æ¥­å‹™ç›¸é—œçš„å¿«é€Ÿå›å¾©æ¨¡æ¿
export const quickResponses = {
    greeting: 'æ‚¨å¥½ï¼æˆ‘æ˜¯è‘£å¨˜çš„åŠ©ç†ï¼Œå¾ˆé«˜èˆˆç‚ºæ‚¨æœå‹™ï¼æˆ‘å¯ä»¥å¹«æ‚¨è™•ç†è¨‚å–®æŸ¥è©¢ã€åº«å­˜ç®¡ç†ã€å®¢æˆ¶æœå‹™ç­‰å„ç¨®æ¥­å‹™å•é¡Œã€‚è«‹å‘Šè¨´æˆ‘æ‚¨éœ€è¦ä»€éº¼å¹«åŠ©ï¼Ÿ',

    orderStatus: 'è®“æˆ‘ç‚ºæ‚¨æŸ¥è©¢è¨‚å–®ç‹€æ…‹ã€‚è«‹æä¾›è¨‚å–®ç·¨è™Ÿï¼Œæˆ‘æœƒç«‹å³ç‚ºæ‚¨ç¢ºèªé…é€é€²åº¦å’Œé è¨ˆåˆ°é”æ™‚é–“ã€‚',

    inventory: 'é—œæ–¼åº«å­˜æŸ¥è©¢ï¼Œæˆ‘å¯ä»¥å¹«æ‚¨ï¼š\nâ€¢ æª¢æŸ¥å„è¦æ ¼ç“¦æ–¯çš„åº«å­˜æ•¸é‡\nâ€¢ é è­¦ä½åº«å­˜å•†å“\nâ€¢ å»ºè­°è£œè²¨æ™‚æ©Ÿ\nâ€¢ åˆ†æéŠ·å”®è¶¨å‹¢',

    safety: 'ç“¦æ–¯å®‰å…¨éå¸¸é‡è¦ï¼è«‹è¨˜ä½ï¼š\nâ€¢ å®šæœŸæª¢æŸ¥ç“¦æ–¯ç®¡ç·š\nâ€¢ ä½¿ç”¨åˆæ ¼çš„ç“¦æ–¯å™¨å…·\nâ€¢ ä¿æŒé€šé¢¨è‰¯å¥½\nâ€¢ ç™¼ç¾ç•°å‘³ç«‹å³é—œé–‰ç“¦æ–¯\nâ€¢ å®šæœŸæ›´æ›è€åŒ–è¨­å‚™',

    pricing: 'é—œæ–¼åƒ¹æ ¼è³‡è¨Šï¼Œæˆ‘å¯ä»¥æä¾›ï¼š\nâ€¢ å„è¦æ ¼ç“¦æ–¯çš„æœ€æ–°åƒ¹æ ¼\nâ€¢ å¤§é‡æ¡è³¼çš„å„ªæƒ æ–¹æ¡ˆ\nâ€¢ å­£ç¯€æ€§åƒ¹æ ¼èª¿æ•´è³‡è¨Š\nâ€¢ ç«¶çˆ­å°æ‰‹åƒ¹æ ¼åˆ†æ',
};

const GEMINI_API_KEY = process.env.GEMINI_API_KEY || (window as any).GEMINI_API_KEY;
const GEMINI_API_URL = process.env.GEMINI_API_URL || (window as any).GEMINI_API_URL ||
    'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent';

export class GeminiService {
    async chat(message: string, context?: string): Promise<{ message: string; error?: string }> {
        try {
            const res = await axios.post(
                `${GEMINI_API_URL}?key=${GEMINI_API_KEY}`,
                {
                    contents: [
                        { role: 'user', parts: [{ text: context ? `${context}\n${message}` : message }] }
                    ]
                },
                { headers: { 'Content-Type': 'application/json' } }
            );
            const reply = res.data.candidates?.[0]?.content?.parts?.[0]?.text || '';
            return { message: reply };
        } catch (e: any) {
            return { message: '', error: e?.response?.data?.error?.message || e.message };
        }
    }
}
